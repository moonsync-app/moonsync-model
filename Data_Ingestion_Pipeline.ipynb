{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WsMI1GT5xy4f",
        "8Baqj1X8yWV-",
        "-4uyknzb04sc",
        "rWKHy0ofxlpU",
        "fSXi0pAcx2o3",
        "iTSgUk2f2ROs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up environment\n"
      ],
      "metadata": {
        "id": "6dcozkVhxhJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "xSdV_m767DO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    marvin \\\n",
        "    llama-index \\\n",
        "    beautifulsoup4 \\\n",
        "    requests \\\n",
        "    pinecone-client \\\n",
        "    openai \\\n",
        "    llama-index-readers-youtube-transcript"
      ],
      "metadata": {
        "id": "jzx5P7giirlY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set API Keys"
      ],
      "metadata": {
        "id": "ZHDOsZfZ7GPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys\n",
        "import openai\n",
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from getpass import getpass\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key: \")\n",
        "os.environ[\"PINECONE_API_KEY\"] = getpass(\"Please enter your Pinecone API key: \")\n",
        "os.environ[\"MARVIN_OPENAI_API_KEY\"] = getpass(\"Please enter your Marvin API key: \")\n",
        "os.environ[\"CHATPDF_API_KEY\"] = getpass(\"Please enter your ChatPDF API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Ezs2gPuP5FPV",
        "outputId": "bd9007e5-1723-4256-cb1a-13f2b013098d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e6f11d7ec48e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#os.environ[\"CHATPDF_API_KEY\"] = \"sec_X2cUNHv2aFSrka0g9kVQI4LCuRXTp4FK\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your OpenAI API key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PINECONE_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your Pinecone API key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MARVIN_OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your Marvin API key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    832\u001b[0m             warnings.warn(\"The `stream` parameter of `getpass.getpass` will have no effect when using ipykernel\",\n\u001b[1;32m    833\u001b[0m                     UserWarning, stacklevel=2)\n\u001b[0;32m--> 834\u001b[0;31m         return self._input_request(prompt,\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and classify the data"
      ],
      "metadata": {
        "id": "WsMI1GT5xy4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Blogs"
      ],
      "metadata": {
        "id": "8Baqj1X8yWV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define URLs to scrape\n",
        "import requests\n",
        "\n",
        "def generate_urls(base_url, category, start_page=1, max_pages=None):\n",
        "    urls = []\n",
        "    page_number = start_page\n",
        "    while True:\n",
        "        url = f\"{base_url}/category/{category}/page/{page_number}/\"\n",
        "        # Check if the page exists:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            urls.append(url)\n",
        "            if max_pages and len(urls) >= max_pages:\n",
        "                break\n",
        "        else:\n",
        "            break  # Stop if the page does not exist\n",
        "        page_number += 1\n",
        "    return urls\n",
        "\n",
        "def generate_simple_urls(base_url, max_pages=None):\n",
        "    urls = []\n",
        "    page_number = 1\n",
        "    while True:\n",
        "        url = f\"{base_url}page/{page_number}/\"\n",
        "        # Check if the page exists:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            urls.append(url)\n",
        "            if max_pages and len(urls) >= max_pages:\n",
        "                break\n",
        "        else:\n",
        "            break  # Stop if the page does not exist\n",
        "        page_number += 1\n",
        "    return urls\n",
        "\n",
        "# Example usage\n",
        "base_url_aviva = \"https://avivaromm.com\"\n",
        "base_url_brighten = \"https://drbrighten.com/articles/\"\n",
        "\n",
        "# Generate URLs while checking for actual page existence\n",
        "urls_hormone = generate_urls(base_url_aviva, \"balance-your-hormones\", max_pages=50)\n",
        "urls_menstrual = generate_urls(base_url_aviva, \"menstrual-sexual-health\", max_pages=50)\n",
        "urls_conception = generate_urls(base_url_aviva, \"fertility-conception\", max_pages=50)\n",
        "urls_pregnancy = generate_urls(base_url_aviva, \"natural-pregnancy\", max_pages=50)\n",
        "urls_thyroid = generate_urls(base_url_aviva, \"thyroid-support\", max_pages=50)\n",
        "urls_mood = generate_urls(base_url_aviva, \"heal-mind-mood\", max_pages=50)\n",
        "urls_gut = generate_urls(base_url_aviva, \"gut-immunity\", max_pages=50)\n",
        "urls_herbal = generate_urls(base_url_aviva, \"herbal-medicine\", max_pages=50)\n",
        "\n",
        "urls_brighten = generate_simple_urls(base_url_brighten, max_pages=50)\n",
        "\n",
        "all_urls = urls_brighten + urls_hormone + urls_menstrual + urls_conception + urls_pregnancy + urls_thyroid + urls_mood + urls_gut + urls_herbal"
      ],
      "metadata": {
        "id": "xiGtgz04yVQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from llama_index.core import Document\n",
        "\n",
        "def scrape_blog_posts(base_url):\n",
        "    response = requests.get(base_url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    for article in soup.find_all(\"article\"):\n",
        "        title = article.find(\"h2\").text.strip()\n",
        "        url = article.find(\"a\")[\"href\"]\n",
        "\n",
        "        article_response = requests.get(url)\n",
        "        article_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
        "        content = article_soup.find(\"div\", class_=\"entry-content\").text.strip()\n",
        "\n",
        "        # Creating a new document for this article\n",
        "        blog = Document(title=title, text=content, metadata={\"source\": url, \"document_type\": \"professional opinions\"})\n",
        "        blogs_documents.extend(blog)\n",
        "    return blogs_documents\n",
        "\n",
        "blogs_documents = []\n",
        "for url in all_urls:\n",
        "  blogs_documents.extend(scrape_blog_posts(url))"
      ],
      "metadata": {
        "id": "4xbPLxEkyjEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(blogs_documents)"
      ],
      "metadata": {
        "id": "7dpGfgYk2psm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Youtube"
      ],
      "metadata": {
        "id": "-4uyknzb04sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
        "from urllib.parse import quote, urlparse, parse_qs\n",
        "# Uncomment this line if you're running the code in Google Colab to mount your Google Drive.\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Read data from a Google Sheet\n",
        "sheet_id = '14Y91UTR4VXngNDwAL0gaBaPSSy5kcXNBYiuQ3WQ5VZM'\n",
        "sheet_name = 'more content' #replace\n",
        "encoded_sheet_name = quote(sheet_name)  # Encoding the sheet name for URL usage\n",
        "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={encoded_sheet_name}'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Extract the YouTube URLs from the first column (assuming no header, uncomment the next line if there is a header)\n",
        "yturls = df.iloc[:, 0].tolist()\n",
        "\n",
        "# Function to extract video IDs from YouTube URLs\n",
        "def extract_video_id(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    video_id = parse_qs(parsed_url.query).get('v', [None])[0]\n",
        "    return video_id\n",
        "\n",
        "video_ids = [extract_video_id(url) for url in yturls]\n",
        "\n",
        "# Filter out any None values from video_ids\n",
        "video_ids = [video_id for video_id in video_ids if video_id is not None]\n",
        "\n",
        "# Correct the creation of YouTube URLs, removing the incorrect escaping of backslashes\n",
        "ytlinks = [f\"https://www.youtube.com/watch?v={video_id}\" for video_id in video_ids]\n",
        "\n",
        "\n",
        "# Collect categorized documents from academic videos\n",
        "loader = YoutubeTranscriptReader()\n",
        "youtube_documents = loader.load_data(ytlinks=ytlinks)"
      ],
      "metadata": {
        "id": "M6p6pF_F04WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(youtube_documents)"
      ],
      "metadata": {
        "id": "9T7sylHj2kz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Papers"
      ],
      "metadata": {
        "id": "rWKHy0ofxlpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS_dlmVCfE0n",
        "outputId": "2de93540-d5b8-4960-fb9f-025752193593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded successfully. Source ID: src_gpvbPVwZFmOhGU6qcVzf2\n",
            "File uploaded successfully. Source ID: src_u9AgbQt1U2Je3wmZqpLKm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from llama_index.core import Document\n",
        "\n",
        "# Step 1: Define the directory path where your PDF files are stored\n",
        "directory_path = os.path.join(os.getcwd(), \"academic_papers\")\n",
        "\n",
        "# Step 2: API setup\n",
        "upload_url = \"https://api.chatpdf.com/v1/sources/add-file\"\n",
        "query_url = \"https://api.chatpdf.com/v1/chats/message\"\n",
        "api_key =  os.environ.get(\"CHATPDF_API_KEY\")\n",
        "\n",
        "\n",
        "# Step 3: Headers for the API requests\n",
        "upload_headers = {\n",
        "    'x-api-key': api_key\n",
        "}\n",
        "\n",
        "query_headers = {\n",
        "    'x-api-key': api_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "papers_documents = []\n",
        "# Step 4: Iterate over PDF files in the directory\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "\n",
        "        # Step 5: Upload the PDF file\n",
        "        with open(file_path, 'rb') as file:\n",
        "            files = [\n",
        "                ('file', (filename, file, 'application/octet-stream'))\n",
        "            ]\n",
        "            response = requests.post(upload_url, headers=upload_headers, files=files)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                source_id = response.json()['sourceId']\n",
        "                print(f'File uploaded successfully. Source ID: {source_id}')\n",
        "\n",
        "                # Step 6: Prepare and send a single query with multiple requests\n",
        "                data = {\n",
        "                    'sourceId': source_id,\n",
        "                    'messages': [\n",
        "                        {\n",
        "                            'role': \"user\",\n",
        "                            'content': \"give a long summary with key findings, any biology explanations, and implications.\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "                citation_data = {\n",
        "                    'sourceId': source_id,\n",
        "                    'messages': [\n",
        "                        {\n",
        "                            'role': \"user\",\n",
        "                            'content': \"What is the article's MLA citation? Please only provide the citation in the response\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "                response = requests.post(query_url, headers=query_headers, json=data)\n",
        "                citation = requests.post(query_url, headers=query_headers, json=citation_data)\n",
        "                papers_documents.append(Document(text=response.json()['content'], metadata={\"source\": citation.json()['content'], \"document_type\": \"academia\"}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5M0cEKQiqpu",
        "outputId": "83bcc71b-b218-4a43-95d0-127fdb1d6288"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify documents and store in seperate indicies"
      ],
      "metadata": {
        "id": "fSXi0pAcx2o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_category_dict(documents, youtube = False):\n",
        "  category_documents = {}\n",
        "  for document in documents:\n",
        "      content = document.text\n",
        "      categories = classify_content(content)\n",
        "      # Creating a new document for this article\n",
        "      if youtube == True:\n",
        "          new_document = Document(text=content, metadata={\"categories\": categories, \"document_type\": \"professional opinions\", \"source\": f\"https://www.youtube.com/watch?v={document.metadata['video_id']}\"})\n",
        "      else:\n",
        "        new_document = Document(text=content, metadata={\"categories\": categories})\n",
        "\n",
        "      # Categorize this document under each category it belongs to\n",
        "      for category in categories:\n",
        "          if category not in category_documents:\n",
        "              category_documents[category] = []\n",
        "          category_documents[category].append(new_document)\n",
        "  return category_documents"
      ],
      "metadata": {
        "id": "dq3jUrD5x_Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import marvin\n",
        "# Function to classify the content and assign categories\n",
        "def classify_content(content):\n",
        "    categories = marvin.classify(\n",
        "        content,\n",
        "        ['fitness/wellness', 'mood/feeling', 'diet/nutrition', 'general'],\n",
        "        instructions=\"Classify the content into the first three provided categories. If it doesn't fit any category, assign it to 'general'.\"\n",
        "    )\n",
        "    if not isinstance(categories, list):\n",
        "        categories = [categories]\n",
        "    return categories"
      ],
      "metadata": {
        "id": "MsG4kmUk1i_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_category_dict(category_dict):\n",
        "  for category, docs in category_dict.items():\n",
        "    print(f\"Category {category_dict}'{category}': {len(docs)} documents\")"
      ],
      "metadata": {
        "id": "3N84TbJD22q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_blogs = create_category_dict(blogs_documents)\n",
        "print_category_dict(category_blogs)"
      ],
      "metadata": {
        "id": "XiCKbO0320FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_youtube = create_category_dict(youtube_documents, True)\n",
        "print_category_dict(category_youtube)"
      ],
      "metadata": {
        "id": "u4gpjtok3NV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_papers = create_category_dict(papers_documents)\n",
        "print_category_dict(category_papers)"
      ],
      "metadata": {
        "id": "FCGOnPgW3PQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upsert to Pinecone\n"
      ],
      "metadata": {
        "id": "iTSgUk2f2ROs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from pinecone.grpc import PineconeGRPC\n",
        "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "import os\n",
        "\n",
        "# Initialize Pinecone Connection\n",
        "pc = PineconeGRPC(api_key= os.environ.get(\"PINECONE_API_KEY\"))\n",
        "\n",
        "def upsert_documents(category, category_dict):\n",
        "    # Format category name for use in Pinecone index naming\n",
        "    formatted_category = category.replace('/', '-').replace(' ', '-').lower()\n",
        "    index_name = f\"moonsync-index-{formatted_category}\"\n",
        "    pinecone_index = pc.Index(index_name)\n",
        "    print(index_name)\n",
        "\n",
        "    # Initialize VectorStore\n",
        "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "    # Retrieve documents for the current category\n",
        "    documents = category_dict.get(category, [])\n",
        "\n",
        "    # Initialize the vector index\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents, storage_context=storage_context\n",
        "        )"
      ],
      "metadata": {
        "id": "5Oaw3jjJr42e"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_upsert_nodes(category_dict):\n",
        "  for category, docs in category_dict.items():\n",
        "    print(f\"Category '{category}': {len(docs)} documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QT8E-MUUtVvh",
        "outputId": "1f84e9d3-ba74-4d75-cba8-0fb27f42c556"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i3OYlaoj-BM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for category in category_blogs:\n",
        "    upsert_documents(category, category_blogs)\n",
        "\n",
        "print_upsert_nodes(category_blogs)"
      ],
      "metadata": {
        "id": "fFxnn3Ot4FhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in category_youtube:\n",
        "    upsert_documents(category, category_youtube)\n",
        "\n",
        "print_upsert_nodes(category_youtube)"
      ],
      "metadata": {
        "id": "pvjOxgMm4WV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in category_papers:\n",
        "    upsert_documents(category, category_papers)\n",
        "\n",
        "print_upsert_nodes(category_papers)"
      ],
      "metadata": {
        "id": "qyMZo7VN4Wqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}